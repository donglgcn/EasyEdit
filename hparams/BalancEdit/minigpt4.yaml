alg_name: "BalancEdit"
name: hugging_cache/vicuna-7b
model_name: minigpt4
model_class: minigpt4
tokenizer_class: LlamaTokenizer
tokenizer_name: hugging_cache/vicuna-7b
sentence_model_name: hugging_cache/all-MiniLM-L6-v2
device: 0

inner_params:
# - llama_model.model.layers[30].mlp.down_proj.weight
# - llama_model.model.layers[30].mlp.up_proj.weight
# - llama_model.model.layers[31].mlp.down_proj.weight
- llama_model.model.layers[31].mlp.up_proj.weight

edit_lr: 1.0
n_iter: 50
eps: 20.0
dist_fn: euc # euc, mmd, cos
val_init: cold # cold, warm
val_train: sgd # sgd, pert
val_reg: None # early
reg: early_stop # early_stop
replacement: replace_last # replace_last, replace_all, replace_prompt
eps_expand: coverage # , moving_avg, decay
num_pert: 8 # only matters when using perturbation training
dropout: 0.0

# Output
results_dir: ./results

# Multimodal
task_name: "VQA"
qformer_checkpoint: hugging_cache/blip2_pretrained_flant5xxl.pth
qformer_name_or_path: bert-base-uncased
state_dict_file: hugging_cache/eva_vit_g.pth
pretrained_ckpt: hugging_cache/pretrained_minigpt4_7b.pth

# image
coco_image: /localtmp/ktm8eh/datasets/EasyEdit/
rephrase_image: /localtmp/ktm8eh/datasets/EasyEdit/
